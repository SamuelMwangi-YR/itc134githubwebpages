<!DOCTYPE html>
<html lang="en">
<head>
    <title>Future</title>
    <style>
        div {
            margin: 0px auto;
            width: 800px;
        }
        p {
            margin: auto;
            color:rgb(192, 150, 34);
            font-style: oblique;
            font-size: 20px;
        }
        .center {
            height: 80px;
            text-align: center;
        }
        .container {
            height: 30px;
            text-align: center;
            width: 700px; 
        }
        header,nav,footer {
            background-color: rgb(105, 26, 26);
            text-align: center;
            font-size: 15px;
        }
        h2 {
            font-style: oblique;
            color: rgb(218, 147, 54);
        }
        h4 {
            font-style: oblique;
            color: rgb(218, 147, 54);
        }
        main {
            margin: auto;
            height: 2400px;
            background-color: white;
            width: 800px;
        }
        section.left {
            text-align: center;
            height: 2400px;
            background-color: rgb(39, 9, 9);
            float: left;
            width: 200px;
        }
        .button {
            display: inline-block;
            font-size: 16px;
            text-align: center;
            background-color:white;
            padding: 6px;
            border-radius: 12px;
        }
        .button:hover{
            background-color:  rgb(192, 150, 34);
        }
        .button:active {
            background-color:rgb(192, 150, 34);
            transform: translateY(4px);
        }
        ul{
            margin: 2px;
            list-style-type: none;
            width: 155px;
            background-color: white;
        }
        li a{
            display: inline-block;
            font-size: 16px;
            text-align: center;
            background-color:white;
            padding: 10px;
            border-radius: 12px; 
        }
        li a:hover{
            background-color:rgb(192, 150, 34);
            width: 100px;
        }
        

    </style>
</head>

<body>
    <div>
    <header>
        <h2>Software Releases</h2>

        <nav>
            <div class="Btn-group">
                <button class="button">
            <a href="https://yukicandelario.github.io/itc134githubwebpages/softwareReleases.html" title="home"><strong>Home</strong></a></button>&nbsp;&nbsp;
                <button class="button">
            <a href="https://docs.google.com/document/d/169MGSTx8UDK0YJni6q-eVt5U4GYS26RJTFIIhqE8NiM/edit?usp=sharing" target="_blank" title="google"><strong>Google Document</strong></a></button>&nbsp;&nbsp;
            </div>
        </nav>
    
    </header>

    <main>
        <section class="left">
            <br>
            <p>&#10553; Links</p>
            <hr>
            <ul>
                <li>
                    <a href="https://yukicandelario.github.io/itc134githubwebpages/history.html" title="History Link">History</a>&nbsp;&nbsp;
                </li>
                <li>
                    <a href="https://yukicandelario.github.io/itc134githubwebpages/present.html" title="Present Link">Present</a>&nbsp;&nbsp;
                </li>
                <li>
                    <a href="https://yukicandelario.github.io/itc134githubwebpages/futuresoftware.html" title="Future Link">Future</a>&nbsp;&nbsp;
                </li>
                <li>
                    <a href="https://yukicandelario.github.io/itc134githubwebpages/careersoftware.html" title="Career Link">Careers</a>&nbsp;&nbsp;
                </li>
            </ul>
        </section>
        <section class="center">
            <div class="container">
                <h2>Future of Software Releases</h2>
                <h3>By: Mwangi Samuel Njoroge</h3>
                <h4>The future of hardware is AI</h4>
                
                    
                       <p>AI workloads are different from the calculations most of our current computers are built to perform. AI implies prediction, inference, and intuition. But the most creative machine learning algorithms are hamstrung by machines that can't harness their power. Hence, if we're to make great strides in AI, our hardware must change, too. Starting with GPUs, and then evolving to analog devices, and then fault-tolerant quantum computers. First, we'll utilize GPUs and build new accelerators with conventional CMOS in the near term to continue; second, we'll look for ways to exploit low precision and analog devices to further lower power and improve performance; and then as we enter the quantum computing era, it will potentially offer entirely new approaches. Accelerators on CMOS still have much to achieve because machine learning models can tolerate imprecise computation. In 2015, Suyong Gupta, et al. demonstrated in their ICML paper Deep learning with limited numerical precision that in fact reduced-precision models have equivalent accuracy to today's standard 64 bit, but using as few as 14 bits of floating point precision. We see this reduced precision, faster computation trend contributing to the 2.5X-per-year improvement at least through the year 2022.
                           <br>
                       That gives us about five years to get beyond the von Neumann bottleneck, and to analog devices. Moving data to and from memory slows down deep learning network training. So finding analog devices that can combine memory and computation will be important for neuromorphic computing progress.</p>
            
                <h4>The future of  Software is Neuromorphic Computing</h4>
                
                       <p>Neuromorphic computing, as it sounds, mimics brain cells. Its architecture of interconnected "neurons" replace von-Neumann's back-and-forth bottleneck with low-powered signals that go directly between neurons for more efficient computation. The US Air Force Research Lab is testing a 64-chip array of our IBM TrueNorth Neurosynaptic System designed for deep neural-network inferencing and information discovery. The system uses standard digital CMOS but only consumes 10 watts of energy to power its 64 million neurons and 16 billion synapses.
                           <br>
                       But phase change memory, a next-gen memory material, may be the first analog device optimized for deep learning networks. How does a memory – the very bottleneck of von-Neumann architecture – improve machine learning? Because we've figured out how to bring computation to the memory. Recently, IBM scientists demonstrated in-memory computing with 1 million devices for applications in AI, publishing their results, Temporal correlation detection using computational phase-change memory, in Nature Communications, and also presenting it at the IEDM session Compressed Sensing Recovery using Computational Memory.</p>
                            <br>
                       <p>Analog computing's maturity will extend the 2.5X-per-year machine learning improvement for a few more years, to 2026 or thereabout.
                       While currently utilizing just a few qubits, algorithms run on the free and open IBM Q experience systems are already showing the potential for efficient and effective use in chemistry, optimization, and even machine learning. A paper IBM researchers co-authored with scientists from Raytheon BBN, "Demonstration of quantum advantage in machine learning" in Nature Quantum Information demonstrates how, with only a five superconducting quantum bit processor, the quantum algorithm consistently identified the sequence in up to a 100-fold fewer computational steps and was more tolerant of noise than the classical (non-quantum) algorithm.
                       IBM Q's commercial systems now have 20 qubits, and a prototype 50 qubit device is operational. Its average coherence time of 90µs is also double that of previous systems. But a fault tolerant system that shows a distinct quantum advantage over today's machines is still a work in progress. In the meantime, experimenting with new materials (like the replacement of copper interconnects) is key – as are other crucial chip improvements IBM and its partners presented at IEDM in the name of advancing all computing platforms, from von Neumann, to neuromorphic, and quantum.</p>
                
                <h4>Computer Hardware and Software for the Generation of Virtual Environments</h4>
                     <p>The computer technology that allows us to develop three-dimensional virtual environments (VEs) consists of both hardware and software. The current popular, technical, and scientific interest in VEs is inspired, in large part, by the advent and availability of increasingly powerful and affordable visually oriented, interactive, graphical display systems and techniques. One possible organization of the computer technology for VEs is to decompose it into functional blocks.</p>
                       
            </div>
        </section>
    </main>

    <footer>Copyright &copy; Seattle Central College SD&T SP20</footer>
   </div>
</body>
</html>
